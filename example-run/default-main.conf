#!/bin/bash
# Copyright 2010-2012 Thomas Schoebel-Theuer /  1&1 Internet AG
#
# Copying and distribution of this file, with or without modification,
# are permitted in any medium without royalty provided the copyright
# notice and this notice are preserved.  This file is offered as-is,
# without any warranty.

#####################################################################

## defaults for standalone tests (without modules)

## replay_host_list
##
## Whitespace-separated list of hostnames where blkreplay is run in parallel.
## Each host must be accessible via ssh, without password prompt.
## You may use advanced shell pattern syntax, such as "myhost{17..23}"

replay_host_list="host672 host{675..679}"

## replay_device_list
##
## Whitespace-separated list of devices where blkreplay is run in parallel.
## You may use advanced shell pattern syntax, such as "/dev/drbd{0..3}"
##
## Notice: you will get the CARTESIAN PRODUCT of
## replay_host_list x replay_device_list
## i.e. all devices must occur on each host.
##
## If you need asymmetric combinations, you can omit (comment out)
## replay_device_list and instead denote each individual combination
## by the special syntax
## replay_host_list="host1:/dev/device1 host2:/dev/device2"
## (or similar)

replay_device_list="/dev/dm-{7,9}"

## input_file_list
##
## Whitespace-separated list of *.load.gz files.
## You may use ordinary shell pattern syntax, such
## as "bursts-ultrafine.readwrite.1b.*.load.gz"
## or advanced shell pattern syntax,
## like "bursts-ultrafine.readwrite.1b.{1..9}.load.gz" etc.
##
## If you provide less input files than needed by the cartesian product
## replay_host_list x replay_device_list, the same input files will be
## re-used in a round-robin fashion.
##
## HINT: you can provide an URL for downloading from the internet (even with wildcards),
## such as "http://www.blkreplay.org/loads/natural/1and1/misc/statistik.*.load.gz"
##
## WARNING! running many hosts on a single input file may lead to
## DISTORTIONS, since all load peaks will occur at the same time,
## and the disk seeks / their distances will be duplicated everywhere
## in exactly the same way. As a workaround, see parameter replay_delta below.
##
## WARNING! Mixing fundamentally different loads can lead to
## unintended results! (if you don't know what you are doing)

input_file_list="${base_dir}/example-load/artificial/bursts-ultrafine.readwrite.1b.1.load.gz"

## replay_max_parallelism
##
## When set to values > 0, this reduces the parallelism produced by replay_*_list
## to some smaller value.
##
## This is handy for comparisons between different degrees of replay parallelism,
## without need for reconfiguring the host / devices list each time.

replay_max_parallelism=0 	# means unlimited / only limited by replay_*_list

## output_label
##
## All output files are prefixed with this name.
## Useful for general description of projects etc.

output_label="MYPROJECT"

## output_add_*
##
## When set to 1 or 0, the output filename will (or will not) contain the
## corresponding information.
## Useful for detailed description of your results.
##
## WARNING! disabling the hostname / device can lead to name clashes
## (mutual overwrites) if you start a replay on multiple hosts
## (and/or on multiple devices) in parallel.

output_add_path=1   # the relative path of the leaf directory is added
output_add_host=1   # add hostname where this blkreplay instance is running
output_add_device=1 # add devicename where this blkreplay instance is running
output_add_input=0  # add the input file name

## replay_start
##
## Starting offset in the input file(s), measured in seconds.
## Often this is 0.
## Can be used to "zoom into" any "time window" in the input files
## (when combined with replay_duration)
##
## Notice: this is _uniformly_ for all input files. If you need
## indiviual time windows from each input file, just create specialized
## input files, e.g. using standard Unix tools like head(1) / tail(1) /
## awk(1) / perl / gzip etc.

replay_start=0

## replay_duration
##
## One of the most important parameters, measured in seconds.
##
## Please read the warnings in the documentation about unexpected
## effects of storage virtualization layers, caches etc when this
## parameter is too short.

replay_duration=3600

## replay_delta
##
## As said above, replaying the same input file many times in parallel
## can lead to unintended distortions. Often, you don't have enough
## independent input files to achieve high replay parallelism.
## As a workaround, you may "move on" the time window by the
## distance $replay_delta, i.e. the next host will replay a
## "later" portion of the same input file. Although this is worse
## than having completely independent / uncorrolated input files,
## this is by far better than "common mode".
##
## Warning! please check the length of your input file, whether
## (replay_start + replay_duration + n * replay_delta) fits into
## the total length. Otherwise, your load will be silently lower
## than intended.
##
## Hint: when needed, replay_delta should be as high as possible, in
## order to avoid repetition of the same parts over and over again.

replay_delta=0

## threads
##
## Replay parallelism. Must be between 1 and (almost) 65536.
##
## Typically, the number of threads is limiting the number of
## outstanding IO requests [aka "request queue depth"].
##
## Many people believe "the higher, the better". However,
## beware of hidden overheads (see PDF paper).
##
## Higher numbers will not always lead to better throughput:
## some devices / drivers / IO schedulers will even slow down when
## hammered with too many requests in parallel. Some of these
## bottlenecks may vary with the kernel version (see paper).
##
## Attention! Never pick this parameter "out of thin air".
##
## In order to approximate real life behaviour, you should DEFINITELY
## consider the ACTUAL threading behaviour of your application
## and try to approximate it!
##
## Using a totally different threads= parameter than occurring in
## practice / in YOUR accplication can easily lead to high distortions,
## and even to completely worthless FAKE RESULTS!
##
## If you have a "fork bomb" like Apache, use a high number of threads.
## Typically, a database like mysql has a relatively low number of threads.

threads=512

## fill_{null,random}
##
## Fill the data blocks (besides header/tag information) with
## some defined values, in order to guarantee reproducibility.
##
## Some devices use data compression internally.
## Therefore, it can make a big difference whether the data
## is highly compressible or not.
## 
## Default behaviour (when unset) is same as fill_null=1.
## If in doubt, use fill_random.
##
## Enable only one of them.

#fill_null=1
#fill_random=1

## strong
##
## Conflict handling. Determines the STORAGE SEMANTICS. Details see PDF doc.
##
## One of following conflict tables is used, depending on this setting:
##
## strong=0 :
##
##    conflict? | R | W |
##           ---+---+---+
##           R  | - | - |
##           W  | - | y |
##
## strong=1 :
##
##    conflict? | R | W |
##           ---+---+---+
##           R  | - | y |
##           W  | y | y |
##
## strong=2 :
##
##    conflict? | R | W |
##           ---+---+---+
##           R  | y | y |
##           W  | y | y |
##

strong=1

## cmode
##
## Shorthand for "conflict mode".
## See section about both timely and positionly overlapping
## in the PDF paper, aka "damaged IO".
##
## Following values are possible:
##
## with-conflicts:
##   No countermeasures against damaged IO are taken.
##   This can lead to the highest possible throughput, but your device
##   may behave incorrectly.
##
## with-drop:
##   In case of damaged IO, any conflicting requests are just dropped.
##   [conflicts are determined by the above strong= parameter]
##   This will minimize artificial delays, but at the cost of some
##   distortions from missing requests.
##
## with-partial:
##   In case of damaged IO, the conflicting requests are pushed back
##   to an internal pushback list and re-activated as soon as possible.
##   This gives the best possible throughput while avoiding artificial
##   delays as well as damaged IO.
##
##   Attention! this may INCREASE the IO parallelism [request queue depth]
##   because additional request slots must be reserved in advance
##   (see paper).
##
##   In addition, this may lead to a 2-class treatment of requests, because
##   the pushed-back requests have less chances and are queued more
##   intensively than ordinary requests. If you want to reveal whether your
##   test candidate already has some internal 2-class treatment, don't
##   use this mode (otherwise you cannot distinguish the reasons easily).
##
## with-ordering:
##   In case of damaged IO, the conflicting requests (as well as
##   any later requests) will be delayed until the conflict has gone.
##
##   This can lead to ARTIFICIAL DELAYS, because all following requests
##   are delayed as well.
##
##   This mode is useful for detection of massive problems in the hardware.
##   It is also useful for detection of 2-class request treatment in your
##   test candidate, because the artificial delays are "fairer" than
##   with-partial.
##
##   Since the micro-stalls introduced by this mode are more approximate
##   to "request queue staggering" occurring in practice, this mode
##   is also useful for avoidance of some distortions caused by overload.
##   In some cases, the artificial delays caused by this mode are even
##   BENEFICIAL!

cmode=with-partial

## vmode
##
## Shorthand for "verify mode".
##
## WARNING! switching on verify can lead to serious performance degradation
## (i.e. blkreplay itself may become a bottleneck)
##
## During verify mode, some temporary files
## /tmp/blkreplay.$$/{verify,completion}_table
## are used to store version information about written data.
##
## Depending on the size of the device, this can take considerable space.
## Depending on workingset behaviour, accesses to those temporary files
## can slow down blkreplay considerably (due to additional IO).
##
## Don't use verify mode for benchmarks!
## Use it only for checking / validation!
##
## Following values are possible:
##
## no-overhead:
##   No checks are done. No overhead.
##
## with-verify:
##   Whenver a sector is read which has been written before (some time
##   ago), the sector header is checked for any violations of the
##   storage semantics.
##
## with-final-verify:
##   In addition to with-verify, at the end all touched sector are
##   separately re-read and checked for any mismatches.
##
## with-paranoia:
##   Like with-final-verify, but in addition _all_ written sectors will
##   be _immediately_ re-read and checked.
##   This leads to high distortions of measurements results (because it
##   doubles the IO rates for all writes), but is useful to
##   check the storage semantics even more thoroughly.

vmode=no-overhead

## verbose_script
##
## When set to 1, make shell output more speaking.

verbose_script=0

## verbose
##
## When set to 1, make blkreplay output more speaking.

verbose=0

## start_grace
##
## Over slow networks, it may take some time until all pipes / buffers
## are filled. If the benchmark starts too early, artificial delays
## could result (because the "supply chain" is too slow).
##
## The real starting time of the benchmark will be after this
## (configurable) grace period. Defaults to 15s.
##
## You may need this also in case of laptop disks with a long spin-up
## time.

#start_grace=15

#####################################################################

## some advanced parameters (experts only)

#replay_out_start=""
#omit_tmp_cleanup=0
#enable_compress_ssh=2

#no_o_direct=0 # extremely dangerous, leads to FAKE results! read the docs!
#o_sync=0      # leads to distortions
#speedup=1.0   # leads to heavy distortions of NATURAL loads
#dry_run=0
#fake_io=0
#ahead_limit=1.000000000
#simulate_io=0.001000000
#fan_out=8
#no_dispatcher=0
#bottleneck=0
